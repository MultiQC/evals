{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Iceberg + Trino Performance Evaluation\n",
    "\n",
    "This notebook compares the performance of Apache Iceberg with Trino against the current Parquet implementation for handling MultiQC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import requests\n",
    "import trino\n",
    "from trino.auth import BasicAuthentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters\n",
    "\n",
    "Let's set up the parameters for our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for data generation\n",
    "NUM_RUNS = 10  # Can be scaled up to millions in real case\n",
    "NUM_MODULES = 10  # Fixed across runs\n",
    "NUM_SAMPLES_PER_MODULE = 100  # Can be 10 to 1000\n",
    "NUM_METRICS_PER_MODULE = 20  # Can be 10 to 50\n",
    "\n",
    "# Paths\n",
    "PARQUET_PATH = \"s3://megaqc-test/parquet_data\"\n",
    "ICEBERG_PATH = \"s3://megaqc-test/iceberg_data\"\n",
    "\n",
    "# Trino connection parameters\n",
    "TRINO_HOST = \"trino-coordinator\"\n",
    "TRINO_PORT = 8080\n",
    "TRINO_USER = \"trino\"\n",
    "TRINO_CATALOG = \"iceberg\"\n",
    "TRINO_SCHEMA = \"default\"\n",
    "\n",
    "# Set MinIO credentials for local testing\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n",
    "# os.environ[\"AWS_ENDPOINT_URL\"] = \"http://minio:9000\"\n",
    "# os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation Functions\n",
    "\n",
    "Reusing the functions from the original Parquet stress test notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample flattened data (first 2 records):\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_0', 'module_name': 'Module 0', 'module_url': 'http://example.com/module/0', 'module_comment': 'This is module 0', 'sample_id': 'VUIkwcXzPQ', 'metric_name': 'metric_0', 'value': 21.03620624291551, 'unmodified_value': 21.03620624291551, 'formatted_value': '21.04', 'metric_min': 3.858724894641228, 'metric_max': 92.3779745348826, 'metric_scale': 'log', 'metric_color': '#3e8155', 'metric_type': 'categorical', 'metric_namespace': 'quality', 'metric_placement': 'tertiary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_0', 'module_name': 'Module 0', 'module_url': 'http://example.com/module/0', 'module_comment': 'This is module 0', 'sample_id': 'VUIkwcXzPQ', 'metric_name': 'metric_1', 'value': 91.61862585210882, 'unmodified_value': 91.61862585210882, 'formatted_value': '91.62', 'metric_min': 8.157002398436372, 'metric_max': 95.80227749604559, 'metric_scale': 'log', 'metric_color': '#e93eea', 'metric_type': 'categorical', 'metric_namespace': 'performance', 'metric_placement': 'primary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_0', 'module_name': 'Module 0', 'module_url': 'http://example.com/module/0', 'module_comment': 'This is module 0', 'sample_id': 'BJmIeYRGiQ', 'metric_name': 'metric_0', 'value': 71.26930418855551, 'unmodified_value': 71.26930418855551, 'formatted_value': '71.27', 'metric_min': 3.858724894641228, 'metric_max': 92.3779745348826, 'metric_scale': 'log', 'metric_color': '#3e8155', 'metric_type': 'categorical', 'metric_namespace': 'quality', 'metric_placement': 'tertiary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_0', 'module_name': 'Module 0', 'module_url': 'http://example.com/module/0', 'module_comment': 'This is module 0', 'sample_id': 'BJmIeYRGiQ', 'metric_name': 'metric_1', 'value': 19.40969667932846, 'unmodified_value': 19.40969667932846, 'formatted_value': '19.41', 'metric_min': 8.157002398436372, 'metric_max': 95.80227749604559, 'metric_scale': 'log', 'metric_color': '#e93eea', 'metric_type': 'categorical', 'metric_namespace': 'performance', 'metric_placement': 'primary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_0', 'module_name': 'Module 0', 'module_url': 'http://example.com/module/0', 'module_comment': 'This is module 0', 'sample_id': 'oZTfCKDiiy', 'metric_name': 'metric_0', 'value': 74.21961826009391, 'unmodified_value': 74.21961826009391, 'formatted_value': '74.22', 'metric_min': 3.858724894641228, 'metric_max': 92.3779745348826, 'metric_scale': 'log', 'metric_color': '#3e8155', 'metric_type': 'categorical', 'metric_namespace': 'quality', 'metric_placement': 'tertiary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_0', 'module_name': 'Module 0', 'module_url': 'http://example.com/module/0', 'module_comment': 'This is module 0', 'sample_id': 'oZTfCKDiiy', 'metric_name': 'metric_1', 'value': 40.77879782064006, 'unmodified_value': 40.77879782064006, 'formatted_value': '40.78', 'metric_min': 8.157002398436372, 'metric_max': 95.80227749604559, 'metric_scale': 'log', 'metric_color': '#e93eea', 'metric_type': 'categorical', 'metric_namespace': 'performance', 'metric_placement': 'primary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_1', 'module_name': 'Module 1', 'module_url': 'http://example.com/module/1', 'module_comment': 'This is module 1', 'sample_id': 'xeLPgSYZEG', 'metric_name': 'metric_0', 'value': 64.76155004769905, 'unmodified_value': 64.76155004769905, 'formatted_value': '64.76', 'metric_min': 4.20517381479241, 'metric_max': 98.95487844200338, 'metric_scale': 'log', 'metric_color': '#babed3', 'metric_type': 'percentage', 'metric_namespace': 'performance', 'metric_placement': 'primary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_1', 'module_name': 'Module 1', 'module_url': 'http://example.com/module/1', 'module_comment': 'This is module 1', 'sample_id': 'xeLPgSYZEG', 'metric_name': 'metric_1', 'value': 36.783069889919595, 'unmodified_value': 36.783069889919595, 'formatted_value': '36.78', 'metric_min': 7.58823274385847, 'metric_max': 98.10175243131393, 'metric_scale': 'log', 'metric_color': '#6ec2eb', 'metric_type': 'percentage', 'metric_namespace': 'quality', 'metric_placement': 'secondary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_1', 'module_name': 'Module 1', 'module_url': 'http://example.com/module/1', 'module_comment': 'This is module 1', 'sample_id': 'HmOOZNaCNj', 'metric_name': 'metric_0', 'value': 30.162862401295275, 'unmodified_value': 30.162862401295275, 'formatted_value': '30.16', 'metric_min': 4.20517381479241, 'metric_max': 98.95487844200338, 'metric_scale': 'log', 'metric_color': '#babed3', 'metric_type': 'percentage', 'metric_namespace': 'performance', 'metric_placement': 'primary'}\n",
      "{'run_id': 'run_0', 'timestamp': '2025-04-23T13:46:05.412019', 'module_id': 'module_1', 'module_name': 'Module 1', 'module_url': 'http://example.com/module/1', 'module_comment': 'This is module 1', 'sample_id': 'HmOOZNaCNj', 'metric_name': 'metric_1', 'value': 19.303018953582708, 'unmodified_value': 19.303018953582708, 'formatted_value': '19.30', 'metric_min': 7.58823274385847, 'metric_max': 98.10175243131393, 'metric_scale': 'log', 'metric_color': '#6ec2eb', 'metric_type': 'percentage', 'metric_namespace': 'quality', 'metric_placement': 'secondary'}\n"
     ]
    }
   ],
   "source": [
    "def generate_random_string(length=10):\n",
    "    \"\"\"Generate a random string of fixed length\"\"\"\n",
    "    return \"\".join(random.choices(string.ascii_letters, k=length))\n",
    "\n",
    "\n",
    "def generate_metric_metadata():\n",
    "    \"\"\"Generate metadata for a metric\"\"\"\n",
    "    return {\n",
    "        \"min\": random.uniform(0, 10),\n",
    "        \"max\": random.uniform(90, 100),\n",
    "        \"scale\": random.choice([\"linear\", \"log\"]),\n",
    "        \"color\": f\"#{random.randint(0, 0xFFFFFF):06x}\",\n",
    "        \"type\": random.choice([\"numeric\", \"categorical\", \"percentage\"]),\n",
    "        \"namespace\": random.choice([\"performance\", \"quality\", \"resource\"]),\n",
    "        \"placement\": random.choice([\"primary\", \"secondary\", \"tertiary\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_value_metadata(value):\n",
    "    \"\"\"Generate metadata for a value\"\"\"\n",
    "    return {\n",
    "        \"unmodified_value\": value,\n",
    "        \"formatted_value\": f\"{value:.2f}\" if isinstance(value, float) else str(value),\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_sample_data(num_metrics):\n",
    "    \"\"\"Generate data for a single sample\"\"\"\n",
    "    sample_id = generate_random_string()\n",
    "    metrics = {}\n",
    "\n",
    "    for i in range(num_metrics):\n",
    "        metric_name = f\"metric_{i}\"\n",
    "        value = random.uniform(0, 100)\n",
    "        metrics[metric_name] = {\n",
    "            \"value\": value,\n",
    "            \"metadata\": generate_value_metadata(value),\n",
    "        }\n",
    "\n",
    "    return {\"sample_id\": sample_id, \"metrics\": metrics}\n",
    "\n",
    "\n",
    "def generate_module_data(module_index, num_samples, num_metrics):\n",
    "    \"\"\"Generate data for a single module\"\"\"\n",
    "    samples = [generate_sample_data(num_metrics) for _ in range(num_samples)]\n",
    "\n",
    "    metrics_metadata = {}\n",
    "    for i in range(num_metrics):\n",
    "        metric_name = f\"metric_{i}\"\n",
    "        metrics_metadata[metric_name] = generate_metric_metadata()\n",
    "\n",
    "    return {\n",
    "        \"module_id\": f\"module_{module_index}\",\n",
    "        \"name\": f\"Module {module_index}\",\n",
    "        \"url\": f\"http://example.com/module/{module_index}\",\n",
    "        \"comment\": f\"This is module {module_index}\",\n",
    "        \"metrics_metadata\": metrics_metadata,\n",
    "        \"samples\": samples,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_run_data(\n",
    "    run_index, num_modules, num_samples_per_module, num_metrics_per_module\n",
    "):\n",
    "    \"\"\"Generate data for a single run\"\"\"\n",
    "    modules = [\n",
    "        generate_module_data(i, num_samples_per_module, num_metrics_per_module)\n",
    "        for i in range(num_modules)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"run_id\": f\"run_{run_index}\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"modules\": modules,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_all_data(\n",
    "    num_runs, num_modules, num_samples_per_module, num_metrics_per_module\n",
    "):\n",
    "    \"\"\"Generate all runs data\"\"\"\n",
    "    return [\n",
    "        generate_run_data(\n",
    "            i, num_modules, num_samples_per_module, num_metrics_per_module\n",
    "        )\n",
    "        for i in range(num_runs)\n",
    "    ]\n",
    "\n",
    "\n",
    "def flatten_hierarchical_data(data):\n",
    "    \"\"\"Convert hierarchical data to flat format for storage\"\"\"\n",
    "    flat_records = []\n",
    "\n",
    "    for run in data:\n",
    "        run_id = run[\"run_id\"]\n",
    "        timestamp = run[\"timestamp\"]\n",
    "\n",
    "        for module in run[\"modules\"]:\n",
    "            module_id = module[\"module_id\"]\n",
    "            module_name = module[\"name\"]\n",
    "            module_url = module[\"url\"]\n",
    "            module_comment = module[\"comment\"]\n",
    "\n",
    "            for sample in module[\"samples\"]:\n",
    "                sample_id = sample[\"sample_id\"]\n",
    "\n",
    "                for metric_name, metric_data in sample[\"metrics\"].items():\n",
    "                    value = metric_data[\"value\"]\n",
    "                    unmodified_value = metric_data[\"metadata\"][\"unmodified_value\"]\n",
    "                    formatted_value = metric_data[\"metadata\"][\"formatted_value\"]\n",
    "\n",
    "                    # Get metric metadata\n",
    "                    metric_metadata = module[\"metrics_metadata\"].get(metric_name, {})\n",
    "\n",
    "                    flat_records.append(\n",
    "                        {\n",
    "                            \"run_id\": run_id,\n",
    "                            \"timestamp\": timestamp,\n",
    "                            \"module_id\": module_id,\n",
    "                            \"module_name\": module_name,\n",
    "                            \"module_url\": module_url,\n",
    "                            \"module_comment\": module_comment,\n",
    "                            \"sample_id\": sample_id,\n",
    "                            \"metric_name\": metric_name,\n",
    "                            \"value\": value,\n",
    "                            \"unmodified_value\": unmodified_value,\n",
    "                            \"formatted_value\": formatted_value,\n",
    "                            \"metric_min\": metric_metadata.get(\"min\"),\n",
    "                            \"metric_max\": metric_metadata.get(\"max\"),\n",
    "                            \"metric_scale\": metric_metadata.get(\"scale\"),\n",
    "                            \"metric_color\": metric_metadata.get(\"color\"),\n",
    "                            \"metric_type\": metric_metadata.get(\"type\"),\n",
    "                            \"metric_namespace\": metric_metadata.get(\"namespace\"),\n",
    "                            \"metric_placement\": metric_metadata.get(\"placement\"),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    return flat_records\n",
    "\n",
    "# Generate a small dataset as an example\n",
    "NUM_RUNS = 2\n",
    "NUM_MODULES = 2\n",
    "NUM_SAMPLES_PER_MODULE = 3\n",
    "NUM_METRICS_PER_MODULE = 2\n",
    "\n",
    "data = generate_all_data(\n",
    "    NUM_RUNS, NUM_MODULES, NUM_SAMPLES_PER_MODULE, NUM_METRICS_PER_MODULE\n",
    ")\n",
    "flat_data = flatten_hierarchical_data(data)\n",
    "\n",
    "# Print first 2 records\n",
    "print(\"Sample flattened data (first 2 records):\")\n",
    "for record in flat_data[:10]:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "PARQUET BENCHMARK\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Generating sample data with:\n",
      "- 5 runs\n",
      "- 5 modules per run\n",
      "- 10 samples per module\n",
      "- 5 metrics per module\n",
      "Flattening data...\n",
      "Creating DataFrame...\n",
      "Creating Parquet Table...\n",
      "Writing to Parquet file s3://megaqc-test/parquet_data/2025-04-23-13-46-14...\n",
      "Parquet storage time: 7.2234 seconds\n",
      "\n",
      "Running query benchmarks:\n",
      "Querying Parquet files for metrics with name: metric_0\n",
      "Query found 250 records in 1.2624 seconds\n",
      "Querying Parquet files for run_id=run_0 and module_id=module_0\n",
      "Query found 50 records in 1.2209 seconds\n",
      "\n",
      "PARQUET BENCHMARK SUMMARY:\n",
      "Storage time: 7.2234 seconds\n",
      "Query by metric time: 1.2624 seconds\n",
      "Query by module time: 1.2209 seconds\n"
     ]
    }
   ],
   "source": [
    "# Benchmark script for Parquet storage and querying\n",
    "\n",
    "def store_in_parquet(data, parquet_dir):\n",
    "    \"\"\"Store the flattened data in Parquet format\"\"\"\n",
    "    print(\"Flattening data...\")\n",
    "    flat_data = flatten_hierarchical_data(data)\n",
    "    print(\"Creating DataFrame...\")\n",
    "    df = pd.DataFrame(flat_data)\n",
    "    print(\"Creating Parquet Table...\")\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    \n",
    "    # Write to Parquet file with partitioning\n",
    "    start_time = time.time()\n",
    "    print(f\"Writing to Parquet file {parquet_dir}...\")\n",
    "    pq.write_to_dataset(\n",
    "        table,\n",
    "        root_path=parquet_dir,\n",
    "        partition_cols=[\"run_id\"],\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    print(f\"Parquet storage time: {elapsed:.4f} seconds\")\n",
    "\n",
    "    return elapsed\n",
    "\n",
    "\n",
    "def query_single_metric_parquet(parquet_dir, metric_name=\"metric_0\"):\n",
    "    \"\"\"Query Parquet files to retrieve specific metric values using PyArrow\"\"\"\n",
    "    print(f\"Querying Parquet files for metrics with name: {metric_name}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Read the Parquet files with partitioning information\n",
    "    dataset = ds.dataset(parquet_dir, format=\"parquet\", partitioning=\"hive\")\n",
    "\n",
    "    # Define filter condition for the metric name\n",
    "    filter_expr = (ds.field(\"metric_name\") == metric_name)\n",
    "    # Read the filtered data\n",
    "    table = dataset.to_table(filter=filter_expr)\n",
    "    # Convert to pandas DataFrame if needed\n",
    "    df = table.to_pandas()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    \n",
    "    print(f\"Query found {len(df)} records in {elapsed:.4f} seconds\")\n",
    "    return df, elapsed\n",
    "\n",
    "\n",
    "def query_single_module_parquet(parquet_dir, run_id=\"run_0\", module_id=\"module_0\"):\n",
    "    \"\"\"Query Parquet files to retrieve specific module data using PyArrow\"\"\"\n",
    "    print(f\"Querying Parquet files for run_id={run_id} and module_id={module_id}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Read the Parquet files with partitioning information\n",
    "    dataset = ds.dataset(parquet_dir, format=\"parquet\", partitioning=\"hive\")\n",
    "\n",
    "    # Define filter condition for the run_id and module_id\n",
    "    filter_expr = (ds.field(\"run_id\") == run_id) & (ds.field(\"module_id\") == module_id)\n",
    "    # Read the filtered data\n",
    "    table = dataset.to_table(filter=filter_expr)\n",
    "    # Convert to pandas DataFrame if needed\n",
    "    df = table.to_pandas()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    \n",
    "    print(f\"Query found {len(df)} records in {elapsed:.4f} seconds\")\n",
    "    return df, elapsed\n",
    "\n",
    "\n",
    "def run_parquet_benchmark(parquet_dir, num_runs=10, num_modules=10, \n",
    "                         num_samples_per_module=100, num_metrics_per_module=20):\n",
    "    \"\"\"Run a complete Parquet benchmark\"\"\"\n",
    "    print(\"-\" * 80)\n",
    "    print(\"PARQUET BENCHMARK\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(f\"\\nGenerating sample data with:\")\n",
    "    print(f\"- {num_runs} runs\")\n",
    "    print(f\"- {num_modules} modules per run\")\n",
    "    print(f\"- {num_samples_per_module} samples per module\")\n",
    "    print(f\"- {num_metrics_per_module} metrics per module\")\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_all_data(\n",
    "        num_runs, num_modules, num_samples_per_module, num_metrics_per_module\n",
    "    )\n",
    "    \n",
    "    # Storage benchmark\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    benchmark_dir = f\"{parquet_dir}/{current_time}\"\n",
    "    storage_time = store_in_parquet(data, benchmark_dir)\n",
    "    \n",
    "    # Query benchmarks\n",
    "    print(\"\\nRunning query benchmarks:\")\n",
    "    \n",
    "    # Query by metric name\n",
    "    _, metric_query_time = query_single_metric_parquet(benchmark_dir)\n",
    "    \n",
    "    # Query by run_id and module_id\n",
    "    _, module_query_time = query_single_module_parquet(benchmark_dir)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nPARQUET BENCHMARK SUMMARY:\")\n",
    "    print(f\"Storage time: {storage_time:.4f} seconds\")\n",
    "    print(f\"Query by metric time: {metric_query_time:.4f} seconds\")\n",
    "    print(f\"Query by module time: {module_query_time:.4f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        \"storage_time\": storage_time,\n",
    "        \"metric_query_time\": metric_query_time,\n",
    "        \"module_query_time\": module_query_time\n",
    "    }\n",
    "\n",
    "\n",
    "# MinIO/S3 configuration\n",
    "PARQUET_PATH = \"s3://megaqc-test/parquet_data\"\n",
    "\n",
    "# Set MinIO credentials for local testing\n",
    "# If using AWS S3 directly, these would be your AWS credentials\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n",
    "# os.environ[\"AWS_ENDPOINT_URL\"] = \"http://minio:9000\"\n",
    "# os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
    "\n",
    "# Run the benchmark with smaller dataset for testing\n",
    "results = run_parquet_benchmark(\n",
    "    PARQUET_PATH,\n",
    "    num_runs=5,\n",
    "    num_modules=5,\n",
    "    num_samples_per_module=10,\n",
    "    num_metrics_per_module=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "ICEBERG BENCHMARK\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Generating sample data with:\n",
      "- 5 runs\n",
      "- 5 modules per run\n",
      "- 10 samples per module\n",
      "- 5 metrics per module\n",
      "Connected to Trino successfully!\n",
      "Error creating Iceberg table: failed to execute: HTTPConnectionPool(host='trino-coordinator', port=8080): Max retries exceeded with url: /v1/statement (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x113ee9760>: Failed to resolve 'trino-coordinator' ([Errno 8] nodename nor servname provided, or not known)\"))\n",
      "Failed to initialize Iceberg schema. Aborting Iceberg benchmark.\n"
     ]
    }
   ],
   "source": [
    "# Benchmark script for Iceberg storage and querying with Trino\n",
    "\n",
    "def create_trino_connection(\n",
    "        host=\"trino-coordinator\", port=8080, \n",
    "        user=\"trino\", catalog=\"iceberg\", schema=\"default\"\n",
    "    ):\n",
    "    \"\"\"Create a connection to Trino\"\"\"\n",
    "    try:\n",
    "        conn = trino.dbapi.connect(\n",
    "            host=host,\n",
    "            port=port,\n",
    "            user=user,\n",
    "            catalog=catalog,\n",
    "            schema=schema,\n",
    "        )\n",
    "        print(\"Connected to Trino successfully!\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Trino: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def init_iceberg_schema(conn):\n",
    "    \"\"\"Initialize Iceberg schema and table\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        # Create the table in Iceberg format\n",
    "        cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS metrics (\n",
    "            run_id VARCHAR,\n",
    "            timestamp VARCHAR,\n",
    "            module_id VARCHAR,\n",
    "            module_name VARCHAR,\n",
    "            module_url VARCHAR,\n",
    "            module_comment VARCHAR,\n",
    "            sample_id VARCHAR,\n",
    "            metric_name VARCHAR,\n",
    "            value DOUBLE,\n",
    "            unmodified_value DOUBLE,\n",
    "            formatted_value VARCHAR,\n",
    "            metric_min DOUBLE,\n",
    "            metric_max DOUBLE,\n",
    "            metric_scale VARCHAR,\n",
    "            metric_color VARCHAR,\n",
    "            metric_type VARCHAR,\n",
    "            metric_namespace VARCHAR,\n",
    "            metric_placement VARCHAR\n",
    "        )\n",
    "        WITH (\n",
    "            format = 'PARQUET',\n",
    "            partitioning = ARRAY['run_id']\n",
    "        )\n",
    "        \"\"\")\n",
    "        print(\"Iceberg table created successfully!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Iceberg table: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def store_in_iceberg(data, conn):\n",
    "    \"\"\"Store the flattened data in Iceberg format using Trino\"\"\"\n",
    "    print(\"Flattening data...\")\n",
    "    flat_data = flatten_hierarchical_data(data)\n",
    "    print(\"Creating DataFrame...\")\n",
    "    df = pd.DataFrame(flat_data)\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Execute insert for each row (not efficient, but works for small dataset)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        print(\"Inserting data into Iceberg table...\")\n",
    "        \n",
    "        # Batch inserts for better performance\n",
    "        batch_size = 1000\n",
    "        total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch_df = df.iloc[i:i+batch_size]\n",
    "            batch_num = i // batch_size + 1\n",
    "            print(f\"Inserting batch {batch_num}/{total_batches}...\")\n",
    "            \n",
    "            for _, row in batch_df.iterrows():\n",
    "                # Create the INSERT statement\n",
    "                insert_sql = \"\"\"\n",
    "                INSERT INTO metrics VALUES (\n",
    "                    %(run_id)s, %(timestamp)s, %(module_id)s, %(module_name)s,\n",
    "                    %(module_url)s, %(module_comment)s, %(sample_id)s, %(metric_name)s,\n",
    "                    %(value)s, %(unmodified_value)s, %(formatted_value)s,\n",
    "                    %(metric_min)s, %(metric_max)s, %(metric_scale)s, %(metric_color)s,\n",
    "                    %(metric_type)s, %(metric_namespace)s, %(metric_placement)s\n",
    "                )\n",
    "                \"\"\"\n",
    "                # Execute the INSERT statement\n",
    "                cursor.execute(insert_sql, {\n",
    "                    'run_id': row['run_id'],\n",
    "                    'timestamp': row['timestamp'],\n",
    "                    'module_id': row['module_id'],\n",
    "                    'module_name': row['module_name'],\n",
    "                    'module_url': row['module_url'],\n",
    "                    'module_comment': row['module_comment'],\n",
    "                    'sample_id': row['sample_id'],\n",
    "                    'metric_name': row['metric_name'],\n",
    "                    'value': row['value'],\n",
    "                    'unmodified_value': row['unmodified_value'],\n",
    "                    'formatted_value': row['formatted_value'],\n",
    "                    'metric_min': row['metric_min'],\n",
    "                    'metric_max': row['metric_max'],\n",
    "                    'metric_scale': row['metric_scale'],\n",
    "                    'metric_color': row['metric_color'],\n",
    "                    'metric_type': row['metric_type'],\n",
    "                    'metric_namespace': row['metric_namespace'],\n",
    "                    'metric_placement': row['metric_placement']\n",
    "                })\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"Iceberg storage time: {elapsed:.4f} seconds\")\n",
    "        return elapsed\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data: {e}\")\n",
    "        return -1\n",
    "\n",
    "\n",
    "def query_single_metric_iceberg(conn, metric_name=\"metric_0\"):\n",
    "    \"\"\"Query Iceberg table to retrieve specific metric values using Trino\"\"\"\n",
    "    print(f\"Querying Iceberg table for metrics with name: {metric_name}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Execute query through Trino\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM metrics\n",
    "        WHERE metric_name = '{metric_name}'\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        # Fetch all results\n",
    "        results = cursor.fetchall()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        \n",
    "        print(f\"Query found {len(df)} records in {elapsed:.4f} seconds\")\n",
    "        return df, elapsed\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying data: {e}\")\n",
    "        return pd.DataFrame(), -1\n",
    "\n",
    "\n",
    "def query_single_module_iceberg(conn, run_id=\"run_0\", module_id=\"module_0\"):\n",
    "    \"\"\"Query Iceberg table to retrieve specific module data using Trino\"\"\"\n",
    "    print(f\"Querying Iceberg table for run_id={run_id} and module_id={module_id}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Execute query through Trino\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM metrics\n",
    "        WHERE run_id = '{run_id}' AND module_id = '{module_id}'\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        # Fetch all results\n",
    "        results = cursor.fetchall()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        \n",
    "        print(f\"Query found {len(df)} records in {elapsed:.4f} seconds\")\n",
    "        return df, elapsed\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying data: {e}\")\n",
    "        return pd.DataFrame(), -1\n",
    "\n",
    "\n",
    "def run_iceberg_benchmark(num_runs=10, num_modules=10, \n",
    "                         num_samples_per_module=100, num_metrics_per_module=20):\n",
    "    \"\"\"Run a complete Iceberg benchmark\"\"\"\n",
    "    print(\"-\" * 80)\n",
    "    print(\"ICEBERG BENCHMARK\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\nGenerating sample data with:\")\n",
    "    print(f\"- {num_runs} runs\")\n",
    "    print(f\"- {num_modules} modules per run\")\n",
    "    print(f\"- {num_samples_per_module} samples per module\")\n",
    "    print(f\"- {num_metrics_per_module} metrics per module\")\n",
    "    \n",
    "    # Generate test data\n",
    "    data = generate_all_data(\n",
    "        num_runs, num_modules, num_samples_per_module, num_metrics_per_module\n",
    "    )\n",
    "    \n",
    "    # Connect to Trino\n",
    "    conn = create_trino_connection()\n",
    "    if not conn:\n",
    "        print(\"Failed to connect to Trino. Aborting Iceberg benchmark.\")\n",
    "        return {\n",
    "            \"storage_time\": -1,\n",
    "            \"metric_query_time\": -1,\n",
    "            \"module_query_time\": -1\n",
    "        }\n",
    "    \n",
    "    # Initialize Iceberg schema\n",
    "    if not init_iceberg_schema(conn):\n",
    "        print(\"Failed to initialize Iceberg schema. Aborting Iceberg benchmark.\")\n",
    "        return {\n",
    "            \"storage_time\": -1,\n",
    "            \"metric_query_time\": -1,\n",
    "            \"module_query_time\": -1\n",
    "        }\n",
    "    \n",
    "    # Clear existing data\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"DELETE FROM metrics\")\n",
    "        print(\"Cleared existing data from metrics table\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing metrics table: {e}\")\n",
    "    \n",
    "    # Storage benchmark\n",
    "    storage_time = store_in_iceberg(data, conn)\n",
    "    \n",
    "    # Query benchmarks\n",
    "    print(\"\\nRunning query benchmarks:\")\n",
    "    \n",
    "    # Query by metric name\n",
    "    _, metric_query_time = query_single_metric_iceberg(conn)\n",
    "    \n",
    "    # Query by run_id and module_id\n",
    "    _, module_query_time = query_single_module_iceberg(conn)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nICEBERG BENCHMARK SUMMARY:\")\n",
    "    print(f\"Storage time: {storage_time:.4f} seconds\")\n",
    "    print(f\"Query by metric time: {metric_query_time:.4f} seconds\")\n",
    "    print(f\"Query by module time: {module_query_time:.4f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        \"storage_time\": storage_time,\n",
    "        \"metric_query_time\": metric_query_time,\n",
    "        \"module_query_time\": module_query_time\n",
    "    }\n",
    "\n",
    "\n",
    "# Run the benchmark with smaller dataset for testing\n",
    "results = run_iceberg_benchmark(\n",
    "    num_runs=5,\n",
    "    num_modules=5,\n",
    "    num_samples_per_module=10,\n",
    "    num_metrics_per_module=5\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TrinoConnectionError",
     "evalue": "failed to execute: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /v1/statement (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1081c19d0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/connection.py:441\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/connection.py:279\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/connection.py:214\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x1081c19d0>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /v1/statement (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1081c19d0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/trino/client.py:883\u001b[0m, in \u001b[0;36mTrinoQuery.execute\u001b[0;34m(self, additional_http_headers)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 883\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_http_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/trino/client.py:634\u001b[0m, in \u001b[0;36mTrinoRequest.post\u001b[0;34m(self, sql, additional_http_headers)\u001b[0m\n\u001b[1;32m    632\u001b[0m http_headers\u001b[38;5;241m.\u001b[39mupdate(additional_http_headers \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[0;32m--> 634\u001b[0m http_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatement_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROXIES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m http_response\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/trino/client.py:1015\u001b[0m, in \u001b[0;36m_retry_with.<locals>.wrapper.<locals>.decorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1015\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/trino/client.py:997\u001b[0m, in \u001b[0;36m_retry_with.<locals>.wrapper.<locals>.decorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 997\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(guard(result) \u001b[38;5;28;01mfor\u001b[39;00m guard \u001b[38;5;129;01min\u001b[39;00m conditions):\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /v1/statement (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1081c19d0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTrinoConnectionError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m conn \u001b[38;5;241m=\u001b[39m trino\u001b[38;5;241m.\u001b[39mdbapi\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[1;32m      3\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8080\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43mCREATE TABLE IF NOT EXISTS metrics (\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m    run_id VARCHAR,\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43m    module_id VARCHAR,\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m    metric_name VARCHAR,\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m    value DOUBLE\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43mWITH (\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43m    format = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPARQUET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m    partitioning = ARRAY[\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/trino/dbapi.py:614\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, params)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query \u001b[38;5;241m=\u001b[39m trino\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mTrinoQuery(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, query\u001b[38;5;241m=\u001b[39moperation,\n\u001b[1;32m    613\u001b[0m                                           legacy_primitive_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_legacy_primitive_types)\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/git/MultiQC/venv312/lib/python3.12/site-packages/trino/client.py:885\u001b[0m, in \u001b[0;36mTrinoQuery.execute\u001b[0;34m(self, additional_http_headers)\u001b[0m\n\u001b[1;32m    883\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query, additional_http_headers)\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m trino\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTrinoConnectionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to execute: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n\u001b[1;32m    886\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request\u001b[38;5;241m.\u001b[39mprocess(response)\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_uri \u001b[38;5;241m=\u001b[39m status\u001b[38;5;241m.\u001b[39minfo_uri\n",
      "\u001b[0;31mTrinoConnectionError\u001b[0m: failed to execute: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /v1/statement (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1081c19d0>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "conn = trino.dbapi.connect(\n",
    "    host=\"localhost\",\n",
    "    port=8080,\n",
    "    user=\"trino\",\n",
    "    catalog=\"iceberg\",\n",
    "    schema=\"default\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS metrics (\n",
    "    run_id VARCHAR,\n",
    "    module_id VARCHAR,\n",
    "    metric_name VARCHAR,\n",
    "    value DOUBLE\n",
    ")\n",
    "WITH (\n",
    "    format = 'PARQUET',\n",
    "    partitioning = ARRAY['run_id']\n",
    ")\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
